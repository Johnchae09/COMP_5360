{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258b9606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/Users/alecchae/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_digits\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scale\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/utils/_param_validation.py:908\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    909\u001b[0m     HasMethods,\n\u001b[1;32m    910\u001b[0m     Hidden,\n\u001b[1;32m    911\u001b[0m     Interval,\n\u001b[1;32m    912\u001b[0m     Options,\n\u001b[1;32m    913\u001b[0m     StrOptions,\n\u001b[1;32m    914\u001b[0m     _ArrayLikes,\n\u001b[1;32m    915\u001b[0m     _Booleans,\n\u001b[1;32m    916\u001b[0m     _Callables,\n\u001b[1;32m    917\u001b[0m     _CVObjects,\n\u001b[1;32m    918\u001b[0m     _InstancesOf,\n\u001b[1;32m    919\u001b[0m     _IterablesNotString,\n\u001b[1;32m    920\u001b[0m     _MissingValues,\n\u001b[1;32m    921\u001b[0m     _NoneConstraint,\n\u001b[1;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[1;32m    923\u001b[0m     _RandomStates,\n\u001b[1;32m    924\u001b[0m     _SparseMatrices,\n\u001b[1;32m    925\u001b[0m     _VerboseHelper,\n\u001b[1;32m    926\u001b[0m     make_constraint,\n\u001b[1;32m    927\u001b[0m     validate_params,\n\u001b[1;32m    928\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/Users/alecchae/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn import tree, svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) \n",
    "\n",
    "# determine the file names of associated player data\n",
    "main_directory = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "data_directory = os.path.join(main_directory, 'data')\n",
    "file_names = [f for f in os.listdir(data_directory) if os.path.isfile(os.path.join(data_directory, f))]\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperates out data associated with total player stats and player stats per game\n",
    "player_stat_total_csv = [file for file in file_names if 'stats.csv' in file]\n",
    "player_stat_pergame_csv = [file for file in file_names if 'game.csv' in file]\n",
    "player_stat_total_csv = player_stat_total_csv[:-2]\n",
    "print(player_stat_total_csv)\n",
    "print(player_stat_pergame_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the name of the headers associated with the data in the csv files (we will do this to ensure that all files are consistent)\n",
    "directory = os.path.join(data_directory, player_stat_total_csv[0])\n",
    "# read the 2000 total player stats into a data frame\n",
    "df = pd.read_csv(directory)\n",
    "# determine the headers of the data frame\n",
    "headers = df.columns\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open all total player stat csv and combine them into one large data frame\n",
    "# define player_stat_df as a dataframe\n",
    "player_stat_df = pd.DataFrame()\n",
    "MVP_player_data = pd.read_csv('MVP player stats.csv')\n",
    "defensive_player_data = pd.read_csv('Defensive Player of the Year player stats.csv')\n",
    "i = 23\n",
    "\n",
    "# for all files in the player_stat_total_csv vector open them and add them to the combined vector\n",
    "for filename in player_stat_total_csv:\n",
    "    # add counter variable so MVP and Denfensive player dataframes can be indexed\n",
    "    i = i - 1\n",
    "    directory = os.path.join(data_directory,filename)\n",
    "    # extract data from one year\n",
    "    df = pd.read_csv(directory)\n",
    "    # extract the year the player data is from\n",
    "    season = (filename[0:2] + filename[3:5])\n",
    "    # add the year to the data frame\n",
    "    df['Year'] = season\n",
    "    # remove the asterisk from the end of players names\n",
    "    df['Player'] = df['Player'].str.replace('*', '')\n",
    "    # current MVP and Defensive player winners\n",
    "    current_MVP = MVP_player_data['Unnamed: 2'][i]\n",
    "    current_defense = defensive_player_data['Unnamed: 2'][i]\n",
    "    # adds information about winners of MVP and Defense award to dataframe\n",
    "    df['MVP Award'] = df['Player'].apply(lambda x: 1 if x == current_MVP else 0)\n",
    "    df['Defensive Award'] = df['Player'].apply(lambda x: 1 if x == current_defense else 0)\n",
    "    # if the data has the correct number of headers it is added to the new dataframe\n",
    "    if len(df.columns) == (len(headers) + 3):\n",
    "        player_stat_df = pd.concat([player_stat_df, df])\n",
    "    else:\n",
    "        print('this file did not match the header ',filename)\n",
    "\n",
    "    \n",
    "player_stat_df = player_stat_df.reset_index(drop=True)\n",
    "display(player_stat_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the last two cell aboves to create a dataframe containing all player stat per game data\n",
    "directory = os.path.join(data_directory, player_stat_pergame_csv[0])\n",
    "df = pd.read_csv(directory)\n",
    "headers = df.columns\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stat_game_df = pd.DataFrame()\n",
    "i = 23\n",
    "\n",
    "# for all files in the player_stat_pergame_csv vector open them and add them to the combined dataframe\n",
    "for filename in player_stat_pergame_csv:\n",
    "    directory = os.path.join(data_directory,filename)\n",
    "    df = pd.read_csv(directory)\n",
    "    # add counter variable so MVP and Denfensive player dataframes can be indexed\n",
    "    i = i - 1\n",
    "    directory = os.path.join(data_directory,filename)\n",
    "    # extract data from one year\n",
    "    df = pd.read_csv(directory)\n",
    "    # extract the year the player data is from\n",
    "    season = (filename[0:2] + filename[3:5])\n",
    "    # add the year to the data frame\n",
    "    df['Year'] = season\n",
    "    # remove the asterisk from the end of players names\n",
    "    df['Player'] = df['Player'].str.replace('*', '')\n",
    "    # current MVP and Defensive player winners\n",
    "    current_MVP = MVP_player_data['Unnamed: 2'][i]\n",
    "    current_defense = defensive_player_data['Unnamed: 2'][i]\n",
    "    # adds information about winners of MVP and Defense award to dataframe\n",
    "    df['MVP Award'] = df['Player'].apply(lambda x: 1 if x == current_MVP else 0)\n",
    "    df['Defensive Award'] = df['Player'].apply(lambda x: 1 if x == current_defense else 0)\n",
    "    # if the data has the correct number of headers it is added to the new dataframe\n",
    "    if len(df.columns) == (len(headers) + 3):\n",
    "        player_stat_game_df = pd.concat([player_stat_game_df, df])\n",
    "    else:\n",
    "        print('this file did not match the header ',filename)\n",
    "    \n",
    "player_stat_game_df = player_stat_game_df.reset_index(drop=True)\n",
    "display(player_stat_game_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new dataframes into a csv\n",
    "player_stat_game_df.to_csv('player_stat_per_game.csv',header=True,index=False)\n",
    "player_stat_df.to_csv('player_stat.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b22ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean total player data\n",
    "# create more valuable column titles\n",
    "name_map = {'Rk':'Rank','Pos':'Position','Tm':'Team','G':'Games','GS':'Games Started','MP':'Total Minutes Played',\n",
    "             'FG':'Total Field Goals','FGA':'Total Field Goal Attempts','FG%':'Field Goal Percentage','3P':'Total 3 Point Field Goals',\n",
    "             '3PA':'Total 3 Point Field Goal Attempts', '3P%':'3 Point Field Goal Percentage','2P':'Total 2 Point Field Goals', '2PA':'Total 2 Point Field Goal Attempts',\n",
    "             '2P%':'2 Point Field Goal Percentage', 'eFG%':'Effective Field Goal Percentage', 'FT':'Total Free Throws',\n",
    "             'FTA':'Total Free Throw Attempts','FT%':'Free Throw Percentage','ORB':'Total Offensive Rebounds','DRB':'Total Defensive Rebounds',\n",
    "             'TRB':'Total Rebounds','AST':'Total Assists','STL':'Total Steals','BLK':'Total Blocks','TOV':'Total Turn Overs',\n",
    "             'PF':'Total Personal Fouls','PTS':'Total Points'}\n",
    "player_stat_df = player_stat_df.rename(columns=name_map)\n",
    "\n",
    "# drop unecessary column\n",
    "player_stat_df = player_stat_df.drop(columns = ['Player-additional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36733077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of NaN values in each column\n",
    "display(player_stat_df.isnull().sum())\n",
    "\n",
    "# visualize where the NaN values are\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(player_stat_df.head(20))\n",
    "\n",
    "# many NaN values are from players with 0 made shots, therefore the make percentage is NaN\n",
    "# the following code will replace the appropriate percentages with 0 in the cases of NaN\n",
    "result = player_stat_df['Total Field Goals'] / player_stat_df['Total Field Goal Attempts']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_df['Field Goal Percentage'] = result\n",
    "\n",
    "result = player_stat_df['Total 3 Point Field Goals'] / player_stat_df['Total 3 Point Field Goal Attempts']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_df['3 Point Field Goal Percentage'] = result\n",
    "\n",
    "result = player_stat_df['Total 2 Point Field Goals'] / player_stat_df['Total 2 Point Field Goal Attempts']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_df['2 Point Field Goal Percentage'] = result\n",
    "\n",
    "result = player_stat_df['Total Free Throws'] / player_stat_df['Total Free Throw Attempts']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_df['Free Throw Percentage'] = result\n",
    "\n",
    "result = (player_stat_df['Total Field Goals'] + 0.5 *  player_stat_df['Total 3 Point Field Goals'])/ player_stat_df['Total Field Goal Attempts']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_df['Effective Field Goal Percentage'] = result\n",
    "\n",
    "# check to make sure that NaN values have been removed\n",
    "display(player_stat_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned player stats to a new csv file\n",
    "player_stat_df.to_csv('cleaned_player_stat.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean player stats per game\n",
    "# create more valuable column titles\n",
    "name_map2 = name_map = {'Rk':'Rank','Pos':'Position','Tm':'Team','G':'Games','GS':'Games Started','MP':'Minutes Played Per Game',\n",
    "             'FG':'Field Goals Per Game','FGA':'Field Goal Attempts Per Game','FG%':'Field Goal Percentage','3P':'3 Point Field Goals Per Game',\n",
    "             '3PA':'3 Point Field Goal Attempts Per Game', '3P%':'3 Point Field Goal Percentage','2P':'2 Point Field Goals Per Game', '2PA':'2 Point Field Goal Attempts Per Game',\n",
    "             '2P%':'2 Point Field Goal Percentage', 'eFG%':'Effective Field Goal Percentage', 'FT':'Free Throws Per Game',\n",
    "             'FTA':'Free Throw Attempts Per Game','FT%':'Free Throw Percentage','ORB':'Offensive Rebounds Per Game','DRB':'Defensive Rebounds Per Game',\n",
    "             'TRB':'Total Rebounds Per Game','AST':'Assists Per Game','STL':'Steals Per Game','BLK':'Blocks Per Game','TOV':'Turn Overs Per Game',\n",
    "             'PF':'Personal Fouls Per Game','PTS':'Points Per Game'}\n",
    "player_stat_game_df = player_stat_game_df.rename(columns=name_map)\n",
    "\n",
    "# drop unecessary column\n",
    "player_stat_game_df = player_stat_game_df.drop(columns = ['Player-additional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of NaN values in each column\n",
    "player_stat_game_df.isnull().sum()\n",
    "\n",
    "# visualize where the NaN values are\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(player_stat_game_df.head(20))\n",
    "\n",
    "# many NaN values are from players with 0 made shots, therefore the make percentage is NaN\n",
    "# the following code will replace the appropriate percentages with 0 in the cases of NaN\n",
    "result = player_stat_game_df['Field Goals Per Game'] / player_stat_game_df['Field Goal Attempts Per Game']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_game_df['Field Goal Percentage'] = result\n",
    "\n",
    "result = player_stat_game_df['3 Point Field Goals Per Game'] / player_stat_game_df['3 Point Field Goal Attempts Per Game']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_game_df['3 Point Field Goal Percentage'] = result\n",
    "\n",
    "result = player_stat_game_df['2 Point Field Goals Per Game'] / player_stat_game_df['2 Point Field Goal Attempts Per Game']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_game_df['2 Point Field Goal Percentage'] = result\n",
    "\n",
    "result = player_stat_game_df['Free Throws Per Game'] / player_stat_game_df['Free Throw Attempts Per Game']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_game_df['Free Throw Percentage'] = result\n",
    "\n",
    "result = (player_stat_game_df['Field Goals Per Game'] + 0.5 *  player_stat_game_df['3 Point Field Goals Per Game'])/ player_stat_game_df['Field Goal Attempts Per Game']\n",
    "result = result.replace([np.inf, -np.inf, np.nan], 0)\n",
    "player_stat_game_df['Effective Field Goal Percentage'] = result\n",
    "\n",
    "player_stat_game_df.to_csv('cleaned_player_stat_per_game.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the average stats for each season\n",
    "# create new player data data frame that only includes columns which we would like to get the seasonal averages of\n",
    "player_stat_game_df2 = player_stat_game_df.drop(columns = ['Player', 'Position', 'Team', 'MVP Award', 'Defensive Award', 'Rank', 'Age'])\n",
    "# create new data frame that contains the seasonal averages of relevant statistics\n",
    "average_stat_game_df = player_stat_game_df2.groupby('Year').mean()\n",
    "# merge original data with season average data\n",
    "merged_data = pd.merge(player_stat_game_df, average_stat_game_df, on='Year', suffixes=('', '_avg'))\n",
    "# divide each statisitic by the corresponding season average\n",
    "for stat in ['Games', 'Games Started', 'Minutes Played Per Game', 'Field Goals Per Game', 'Field Goal Attempts Per Game', 'Field Goal Percentage', '3 Point Field Goals Per Game', '3 Point Field Goal Attempts Per Game', '3 Point Field Goal Percentage', '2 Point Field Goals Per Game', '2 Point Field Goal Attempts Per Game', '2 Point Field Goal Percentage', 'Effective Field Goal Percentage', 'Free Throws Per Game', 'Free Throw Attempts Per Game', 'Free Throw Percentage', 'Offensive Rebounds Per Game', 'Defensive Rebounds Per Game', 'Total Rebounds Per Game', 'Assists Per Game', 'Steals Per Game', 'Blocks Per Game', 'Turn Overs Per Game', 'Personal Fouls Per Game', 'Points Per Game']:\n",
    "    merged_data[stat] = merged_data[stat] / merged_data[f'{stat}_avg']\n",
    "    merged_data.drop(columns=[f'{stat}_avg'], inplace=True)\n",
    "\n",
    "player_average_game_df = merged_data\n",
    "display(player_average_game_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98664023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a heat map to visualize the correlation between variables for both total player stats and player stats per game\n",
    "# remove non numerical data so correlation matrix can be obtained\n",
    "player_stat_game_df2 = player_stat_game_df.drop(columns = ['Player', 'Position', 'Team'])\n",
    "player_stat_df2 = player_stat_df.drop(columns = ['Player', 'Position', 'Team'])\n",
    "\n",
    "# create the correlation matrices\n",
    "corr_matrix_total = player_stat_game_df2.corr(method = 'pearson')\n",
    "corr_matrix_game = player_stat_df2.corr(method = 'pearson')\n",
    "\n",
    "# plot the heat map for total player stats\n",
    "label = ['Rank', 'Age', 'Games', 'Games Started', 'Total Minutes Played', 'Total Field Goals', 'Total Field Goal Attempts', 'Field Goal Percentage',\n",
    "        'Total 3 Point Field Goals', 'Total 3 Point Field Goal Attempts', '3 Point Field Goal Percentage', 'Total 2 Point Field Goals',\n",
    "        'Total 2 Point Field Goal Attempts', '2 Point Field Goal Percentage', 'Effective Field Goal Percentage', 'Total Free Throws',\n",
    "        'Total Free Throw Attempts', 'Free Throw Percentage', 'Total Offensive Rebounds', 'Total Defensive Rebounds', 'Total Rebounds',\n",
    "        'Total Assists', 'Total Steals', 'Total Blocks', 'Total Turnovers', 'Total Personal Fouls', 'Total Points', 'Year', 'MVP Award', 'Defense Award']\n",
    "plt.imshow(corr_matrix_total, vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(label)), label, fontsize = 7, rotation = 'vertical')\n",
    "plt.yticks(np.arange(len(label)), label, fontsize = 7)\n",
    "plt.title('Correlation Matrix For Total Player Stats')\n",
    "plt.show()\n",
    "\n",
    "# plot the heat map for per game player stats\n",
    "label2 = ['Rank', 'Age', 'Games', 'Games Started', 'Minutes Played Per Game', 'Field Goals Per Game', 'Field Goal Attempts Per Game', 'Field Goal Percentage',\n",
    "        '3 Point Field Goals Per Game', '3 Point Field Goal Attempts Per Game', '3 Point Field Goal Percentage', '2 Point Field Goals Per Game',\n",
    "        '2 Point Field Goal Attempts Per Game', '2 Point Field Goal Percentage', 'Effective Field Goal Percentage', 'Free Throws Per Game',\n",
    "        'Free Throw Attempts Per Game', 'Free Throw Percentage', 'Offensive Rebounds Per Game', 'Defensive Rebounds Per Game', 'Rebounds Per Game',\n",
    "        'Assists Per Game', 'Steals Per Game', 'Blocks Per Game', 'Turnovers Per Game', 'Personal Fouls Per Game', 'Points Per Game', 'Year', 'MVP Award', 'Defense Award']\n",
    "plt.imshow(corr_matrix_game, vmin = -1, vmax = 1)\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(label2)), label2, fontsize = 7, rotation = 'vertical')\n",
    "plt.yticks(np.arange(len(label2)), label2, fontsize = 7)\n",
    "plt.title('Correlation Matrix For Average Player Stats Per Game')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ff7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot matrix for total player stats while highlighting MVP winners\n",
    "# create new dataframe so only helpful columns are included in the scatter plot matrix\n",
    "# player_stat_game_df3 = player_stat_game_df[['Games', 'Minutes Played Per Game', 'Field Goal Percentage', '3 Point Field Goal Percentage',\n",
    "#                                           '2 Point Field Goal Percentage', 'Free Throw Percentage', 'Total Rebounds Per Game', 'Assists Per Game',\n",
    "#                                           'Steals Per Game', 'Blocks Per Game', 'Turn Overs Per Game', 'Personal Fouls Per Game', 'Points Per Game', 'MVP Award', 'Defensive Award']]\n",
    "# plot the scatter matrix\n",
    "# sns.pairplot(player_stat_game_df3, hue = 'MVP Award')\n",
    "# sns.pairplot(player_stat_game_df3, hue = 'Defensive Award')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data frame with predictor data\n",
    "player_average_game_df2 = player_average_game_df.drop(columns = ['Player', 'Position', 'Team', 'MVP Award', 'Defensive Award'])\n",
    "# create data filters for splitting up testing and training data\n",
    "train_years = ['0001', '0102', '0203', '0304', '0405', '0506', '0607', '0708', '0809', '0910', '1011', '1112', '1213', '1314',\n",
    "              '1415', '1516', '1617', '1718', '1819', '1920', '2021']\n",
    "test_year = ['2122']\n",
    "# Filter both x_train and y_train based on train_years\n",
    "x_train = player_average_game_df2[player_average_game_df2['Year'].isin(train_years)].to_numpy()\n",
    "y_train = player_average_game_df[player_average_game_df['Year'].isin(train_years)]['MVP Award'].to_numpy()\n",
    "# Filter both x_test and y_test based on train_years\n",
    "x_test_first = player_average_game_df2[player_average_game_df2['Year'].isin(test_year)].to_numpy()\n",
    "y_test_first = player_average_game_df[player_average_game_df['Year'].isin(test_year)]['MVP Award'].to_numpy()\n",
    "\n",
    "# initialize old confusion matrix and model accuracy\n",
    "confusion_matrix_old = [[0, 100],[0, 0]]\n",
    "model_accuracy = []\n",
    "\n",
    "# for loop used to determine the optimal class weights\n",
    "for i in range(500, 5000, 100):\n",
    "    for j in range(10, 100, 10):\n",
    "        # Define class weights\n",
    "        class_weights = {0: 1, 1: i}\n",
    "        # create svm model\n",
    "        svm_model = svm.SVC(kernel = 'rbf', C = j, gamma = 'scale', class_weight = class_weights)\n",
    "        # train the nearest neighbor model with the training data \n",
    "        svm_model.fit(x_train, y_train)\n",
    "        # get model predictions\n",
    "        y_prediction = svm_model.predict(x_test_first)\n",
    "        # determine the confusion matrix with the confusion_matrix function\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test_first, y_prediction)\n",
    "        # determine ideal parameters\n",
    "        if confusion_matrix[1][1] == 1 and confusion_matrix[0][1] < confusion_matrix_old[0][1]:\n",
    "            best_weight = i\n",
    "            best_c = j\n",
    "            confusion_matrix_old = confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b1df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results from previous cell\n",
    "print('Best Weight: ')\n",
    "print(best_weight)\n",
    "print('Best C Value: ')\n",
    "print(best_c)\n",
    "\n",
    "# develop svm model using the ideal parameters\n",
    "ideal_class_weights = {0:1, 1:best_weight}\n",
    "\n",
    "# develop the ideal svm model\n",
    "svm_model_first = svm.SVC(kernel = 'rbf', C = best_c, gamma = 'scale', class_weight = ideal_class_weights)\n",
    "# train the nearest neighbor model with the training data \n",
    "svm_model_first.fit(x_train, y_train)\n",
    "# get model predictions\n",
    "y_prediction = svm_model_first.predict(x_test_first)\n",
    "# assess accuracy using the accuracy_score function\n",
    "model_accuracy = metrics.accuracy_score(y_test_first, y_prediction)\n",
    "# determine the confusion matrix with the confusion_matrix function\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_first, y_prediction)\n",
    "print('Model Accuracy: ')\n",
    "print(model_accuracy)\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix)\n",
    "\n",
    "# create placeholder data frame that will be used later\n",
    "x_test1 = player_average_game_df2[player_average_game_df2['Year'].isin(test_year)]\n",
    "\n",
    "# Create a DataFrame to store the predictions and corresponding players\n",
    "predictions_df = player_average_game_df.loc[x_test1.index].copy()\n",
    "predictions_df['First Prediction'] = y_prediction\n",
    "\n",
    "# Filter the DataFrame to get the rows where the model predicted MVPs\n",
    "predicted_mvp_df = predictions_df[predictions_df['First Prediction'] == 1]\n",
    "\n",
    "# Print or display the predicted MVP players\n",
    "display(predicted_mvp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell develops a second svm model which is used to predict the MVPs from the pool of previously predicted MVPs\n",
    "# create new test and train data from the results of previous run do this in an effort to decrease number of predicted MVPs\n",
    "x_test_second = predicted_mvp_df.drop(columns = ['First Prediction', 'Player', 'Position', 'Team', 'MVP Award', 'Defensive Award']).to_numpy()\n",
    "y_test_second = predicted_mvp_df['MVP Award'].to_numpy()\n",
    "\n",
    "# initialize old confusion matrix and model accuracy\n",
    "confusion_matrix_old = [[0, 100],[0, 0]]\n",
    "model_accuracy = []\n",
    "\n",
    "# for loop used to determine the optimal class weights\n",
    "for i in range(10, 100, 10):\n",
    "    for j in range(10, 100, 10):\n",
    "        # Define class weights\n",
    "        class_weights = {0: 1, 1: i}\n",
    "        # create svm model\n",
    "        svm_model = svm.SVC(kernel = 'rbf', C = j, gamma = 'scale', class_weight = class_weights)\n",
    "        # train the nearest neighbor model with the training data \n",
    "        svm_model.fit(x_train, y_train)\n",
    "        # get model predictions\n",
    "        y_prediction = svm_model.predict(x_test_second)\n",
    "        # determine the confusion matrix with the confusion_matrix function\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test_second, y_prediction)\n",
    "        # determine ideal parameters\n",
    "        if confusion_matrix[1][1] == 1 and confusion_matrix[0][1] < confusion_matrix_old[0][1]:\n",
    "            best_weight2 = i\n",
    "            best_c2 = j\n",
    "            confusion_matrix_old = confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results from previous cell\n",
    "print('Best Weight: ')\n",
    "print(best_weight2)\n",
    "print('Best C Value: ')\n",
    "print(best_c2)\n",
    "\n",
    "# develop svm model using the ideal parameters\n",
    "ideal_class_weights = {0:1, 1:best_weight2}\n",
    "\n",
    "# develop the ideal svm model\n",
    "svm_model_second = svm.SVC(kernel = 'rbf', C = best_c2, gamma = 'scale', class_weight = ideal_class_weights)\n",
    "# train the nearest neighbor model with the training data \n",
    "svm_model_second.fit(x_train, y_train)\n",
    "# get model predictions\n",
    "y_prediction = svm_model_second.predict(x_test_second)\n",
    "# assess accuracy using the accuracy_score function\n",
    "model_accuracy = metrics.accuracy_score(y_test_second, y_prediction)\n",
    "# determine the confusion matrix with the confusion_matrix function\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_second, y_prediction)\n",
    "print('Model Accuracy: ')\n",
    "print(model_accuracy)\n",
    "print('Confusion Matrix: ')\n",
    "print(confusion_matrix)\n",
    "\n",
    "# add final predicted winners to dataframe\n",
    "predicted_mvp_df.loc[:, 'Second Prediction'] = y_prediction\n",
    "display(predicted_mvp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc394472",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['0001', '0102', '0203', '0304', '0405', '0506', '0607', '0708', '0809', '0910', '1011', '1112', '1213', '1314','1415',\n",
    "         '1516', '1617', '1718', '1819', '1920', '2021', '2122']\n",
    "\n",
    "complete_predicted_mvp_df = pd.DataFrame()\n",
    "complete_predicted_mvp_df = complete_predicted_mvp_df.reindex(columns = predicted_mvp_df.columns)\n",
    "\n",
    "for year in years:\n",
    "    # test model to see how it predicts the winner of each year\n",
    "    x_test_final_first = player_average_game_df2[player_average_game_df2['Year'].isin([year])].to_numpy()\n",
    "    y_test_final_first = player_average_game_df[player_average_game_df['Year'].isin([year])]['MVP Award'].to_numpy()\n",
    "    \n",
    "    # get the prediction from the first model\n",
    "    y_prediction_first = svm_model_first.predict(x_test_final_first)\n",
    "    \n",
    "    # create placeholder data frame that will be used later\n",
    "    x_test1 = player_average_game_df2[player_average_game_df2['Year'].isin([year])]\n",
    "    \n",
    "    # Create a DataFrame to store the predictions and corresponding players\n",
    "    predictions_df = player_average_game_df.loc[x_test1.index].copy()\n",
    "    predictions_df['First Prediction'] = y_prediction_first\n",
    "    \n",
    "    # Filter the DataFrame to get the rows where the model predicted MVPs\n",
    "    predicted_mvp_df = predictions_df[predictions_df['First Prediction'] == 1]\n",
    "    \n",
    "    # create the second set of test data based on results from the first model\n",
    "    x_test_final_second = predicted_mvp_df.drop(columns = ['First Prediction', 'Player', 'Position', 'Team', 'MVP Award', 'Defensive Award']).to_numpy()\n",
    "    y_test_final_second = predicted_mvp_df['MVP Award'].to_numpy()\n",
    "    \n",
    "    # get the prediction from the second model\n",
    "    y_prediction_second = svm_model_second.predict(x_test_final_second)\n",
    "    \n",
    "    # add final predicted winners to dataframe\n",
    "    predicted_mvp_df.loc[:, 'Second Prediction'] = y_prediction_second\n",
    "    \n",
    "    # fill out data frame with all the predicted winners\n",
    "    complete_predicted_mvp_df = pd.concat([complete_predicted_mvp_df, predicted_mvp_df], ignore_index = True)\n",
    "    \n",
    "display(complete_predicted_mvp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how well the two models are able to predict the winner of the MVP award\n",
    "predicted_mvp_winners = complete_predicted_mvp_df[complete_predicted_mvp_df['Second Prediction'] == 1]\n",
    "display(predicted_mvp_winners)\n",
    "num_true_winners = len(years)\n",
    "pred_true_winners = predicted_mvp_winners['MVP Award'].sum()\n",
    "percent_picked_true_winners = (pred_true_winners/num_true_winners)*100\n",
    "print('Percentage that model predicts the true winner: ')\n",
    "print(percent_picked_true_winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01672e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
